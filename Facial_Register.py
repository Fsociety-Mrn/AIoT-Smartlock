# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'Register.ui'
#
# Created by: PyQt5 UI code generator 5.15.9
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets

from Face_Recognition.JoloRecognition import JoloRecognition as JL

import os
import cv2
import time
import dlib
import torch
import numpy as np
import threading


class facialRegister(object):

    def setupUi(self, Frame):
            # message box
            self.MessageBox = QtWidgets.QMessageBox()
            self.MessageBox.setStyleSheet("""
                  QMessageBox { 
                      text-align: center;
                  }
                  QMessageBox::icon {
                      subcontrol-position: center;
                  }
                  QPushButton { 
                      width: 250px; 
                      height: 30px; 
                      font-size: 15px;
                  }
              """)

            # EAR of eye
            self.blink_threshold = 0.3
            self.blink_counter = 0
            self.blink = True

            #frame
            Frame.setObjectName("Facial register")
            Frame.resize(533, 643)
            Frame.setStyleSheet("background-color: qlineargradient(spread:pad, x1:0, y1:0, x2:0.0965909, y2:0.909, stop:0 rgba(61, 152, 154, 255), stop:1 rgba(12, 14, 36, 255));")
          #camera
            self.camera = QtWidgets.QLabel(Frame)
            self.camera.setGeometry(QtCore.QRect(10, 20, 501, 341))
            self.camera.setStyleSheet("color: white;\n""")
            self.camera.setAlignment(QtCore.Qt.AlignCenter)
            self.camera.setObjectName("camera")

            self.cameraStat = False
            self.capture = 1

            # open camera
            self.cap = cv2.VideoCapture(1) if cv2.VideoCapture(1).isOpened() else cv2.VideoCapture(0)
            self.cap.set(4, 1080)

            # face detector: Haar, dlib,landmark
            self.face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            self.dlib_faceDetcetoor = dlib.get_frontal_face_detector()
            self.landmark_detector = dlib.shape_predictor('Model/shape_predictor_68_face_landmarks.dat')

            #status
            self.status = QtWidgets.QLabel(Frame)
            self.status.setGeometry(QtCore.QRect(10, 380, 501, 41))
            self.status.setStyleSheet("color: white;\n""")
            self.status.setAlignment(QtCore.Qt.AlignCenter)
            self.status.setObjectName("status")

            # textbox name
            self.textboxName = QtWidgets.QLineEdit(Frame)
            self.textboxName.setGeometry(QtCore.QRect(10, 460, 511, 61))
            self.textboxName.setStyleSheet("color: white;\n""")
            self.textboxName.setAlignment(QtCore.Qt.AlignCenter)
            self.textboxName.setObjectName("textboxName")

            # create button
            self.create = QtWidgets.QPushButton(Frame)
            self.create.setGeometry(QtCore.QRect(40, 530, 451, 41))
            self.create.setStyleSheet("color: white;\n""")
            self.create.setObjectName("create")
            self.create.clicked.connect(self.createButton)

            # connect the close event to the method
            # Frame.closeEvent = self.closeEvent

            # Timer
            self.timer = QtCore.QTimer(Frame)
            self.timer.timeout.connect(self.videoStreaming)
            self.last_recognition_time = time.time()
            self.timer.start(30)

            self.retranslateUi(Frame)
            QtCore.QMetaObject.connectSlotsByName(Frame)

    def retranslateUi(self, Frame):
                _translate = QtCore.QCoreApplication.translate
                Frame.setWindowTitle(_translate("Frame", "Frame"))

                # for camera
                self.camera.setText(_translate("Frame", "Loading"))

                # message status
                self.status.setText(_translate("Frame", "Please create folder first"))

                # create Button
                self.create.setText(_translate("Frame", "Create folder"))

    def setStatus(self):

                if self.blink:
                    self.status.setText("Please blink")
                    return
                self.status.setText("Training Facial")

            # capture and Train Images
    def captureSave(self, current_time=None, frame=None, gray=None):

                # Check if camera is enabled
                if not self.cameraStat:
                    return

                if self.capture == 19:
                    self.status.setText("Please blink")
                else:
                    self.status.setText(
                        "Training Facial" if self.capture >= 20 else "Face capture left " + str(21 - self.capture))

                # Set time delay to avoid over capturing
                if current_time - self.last_recognition_time <= 0.5:
                    return

                self.last_recognition_time = current_time

                # Save captured images if capture count is less than 20
                if self.capture <= 20:

                    if self.capture == 19:
                        if not self.eyeBlink(frame=frame, gray=gray):
                            path = f"Known_Faces/{self.textboxName.text()}/{self.capture}.png"
                            cv2.imwrite(path, frame)
                            self.capture += 1
                            return
                        else:
                            self.status.setText("Please blink")
                            return

                    path = f"Known_Faces/{self.textboxName.text()}/{self.capture}.png"
                    cv2.imwrite(path, frame)
                    self.capture += 1

                else:

                    # facial training
                    self.facialTraining()

    def facialTraining(self):

                # Train the facial recognition model
                message = JL().Face_Train()

                # Show the result
                title = "Facial Registration"
                text = "Facial training complete" if message == "Successfully trained" else message
                icon = self.MessageBox.Information if message == "Successfully trained" else self.MessageBox.Warning
                self.messageBoxShow(title=title, text=text, buttons=self.MessageBox.Ok, icon=icon)
                self.status.setText("Please create folder first")

                self.textboxName.setText("")

                self.create.setEnabled(True)
                self.textboxName.setReadOnly(False)

                self.cameraStat = False
                self.capture = 1

            # video Streaming
    def videoStreaming(self):
                ret, frame = self.cap.read()

                if not ret:
                    self.camera.setText("Camera wont load")
                    return

                # process the frame
                frame = cv2.flip(frame, 1)

                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

                # load facial detector haar
                faces = self.face_detector.detectMultiScale(gray,
                                                            scaleFactor=1.1,
                                                            minNeighbors=20,
                                                            minSize=(100, 100),
                                                            flags=cv2.CASCADE_SCALE_IMAGE)
                current_time = time.time()

                if len(faces) == 1:
                    x, y, w, h = faces[0]
                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                    self.status.setText("Please create folder first")

                    # if not self.eyeBlink(frame=frame,gray=gray):
                    self.captureSave(current_time=current_time, frame=frame, gray=gray)



                elif len(faces) >= 1:
                    self.status.setText("Multiple face is detected")
                else:
                    self.status.setText("No face is detected")

                height, width, channel = frame.shape
                bytesPerLine = channel * width
                qImg = QtGui.QImage(frame.data, width, height, bytesPerLine, QtGui.QImage.Format_BGR888)
                pixmap = QtGui.QPixmap.fromImage(qImg)
                self.camera.setPixmap(pixmap)

            # message box
    def messageBoxShow(self, icon=None, title=None, text=None, buttons=None):

                # Set the window icon, title, and text
                self.MessageBox.setIcon(icon)
                self.MessageBox.setWindowTitle(title)
                self.MessageBox.setText(text)

                # Set the window size
                self.MessageBox.setFixedWidth(400)

                # Set the standard buttons
                self.MessageBox.setStandardButtons(buttons)

                result = self.MessageBox.exec_()

                self.MessageBox.close()
                # Show the message box and return the result
                return result

            # create folder
    def createButton(self):

                # Define the path for the known faces folder
                path = f"Known_Faces/{self.textboxName.text()}"

                if not self.textboxName.text():
                    self.messageBoxShow(
                        icon=self.MessageBox.Warning,
                        title="Facial Recognition",
                        text="Name cannot be empty",
                        buttons=self.MessageBox.Ok
                    )
                    return

                # Check if the folder already exists
                if os.path.exists(path):
                    # Show a message box indicating that the folder already exists
                    self.messageBoxShow(
                        icon=self.MessageBox.Warning,
                        title="Facial Recognition",
                        text="Folder already exists",
                        buttons=self.MessageBox.Ok
                    )

                    # Disable the push button and plain text edit
                    pushButtonEnabled = False
                    plainTextEditEnabled = False

                    # Set the camera status to true
                    self.cameraStat = False
                else:

                    # Create the known faces folder if it doesn't exist
                    os.makedirs(path, exist_ok=True)

                    # Show a message box indicating that the folder has been created
                    self.messageBoxShow(
                        icon=self.MessageBox.Information,
                        title="Facial Recognition",
                        text="Folder Created please align your face to camera properly",
                        buttons=self.MessageBox.Ok
                    )

                    # Enable the camera and plain text edit
                    pushButtonEnabled = False
                    plainTextEditEnabled = True

                    # Set the camera status to true
                    self.cameraStat = True

                # Update the enabled status of the push button and plain text edit
                self.create.setEnabled(pushButtonEnabled)
                self.textboxName.setReadOnly(plainTextEditEnabled)

            # =================== for eye blinking detection functions =================== #
    def eyeBlink(self, gray, frame):

                # detect eyes using dlib
                faces = self.dlib_faceDetcetoor(gray, 0)

                for face in faces:
                    landmarks = self.landmark_detector(gray, face)

                    # extract eye coordinates from facial landmarks
                    left_eye, right_eye = self.extract_eye_coordinates(landmarks)

                    # calculate eye aspect ratio
                    ear = self.calculate_ear(left_eye, right_eye)

                    # update blink count and status
                    status = self.update_blink_count_and_status(ear)

                    # display blink count, EAR, and eye status on frame
                    self.display_stats_on_frame(frame, ear)

                return status

    def extract_eye_coordinates(self, landmarks):
                left_eye = []
                right_eye = []

                for i in range(36, 42):
                    left_eye.append((landmarks.part(i).x, landmarks.part(i).y))

                for i in range(42, 48):
                    right_eye.append((landmarks.part(i).x, landmarks.part(i).y))

                return left_eye, right_eye

    def EAR_cal(self, eye):
                eye = torch.from_numpy(np.array(eye)).float()

                # ------- verticle ------- #
                v1 = torch.dist(eye[1], eye[5])
                v2 = torch.dist(eye[2], eye[4])

                # ------- horizontal ------- #
                h1 = torch.dist(eye[0], eye[3])

                ear = (v1 + v2) / h1
                return ear

    def calculate_ear(self, left_eye, right_eye):

                LEFT = self.EAR_cal(left_eye)
                RIGHT = self.EAR_cal(right_eye)

                EAR = float((LEFT + RIGHT) / 2.0)

                return round(EAR, 2)

    def update_blink_count_and_status(self, ear):
                if ear < self.blink_threshold:

                    # if eye is once Open
                    if self.blink:
                        self.blink_counter += 1
                        self.blink = False
                        return False
                else:
                    # if eye is open
                    self.blink = True
                    return True

    def display_stats_on_frame(self, frame, EAR):
                # cv2.putText(frame, "Blink Counter: {}".format(self.blink_counter), (80, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(200, 200, 0), 2)
                # cv2.putText(frame, "EAR: {}".format(EAR), (80, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(200, 200, 0), 2)
                cv2.putText(frame, "Eye Status: {}".format(self.blink), (80, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                            (200, 200, 0), 2)

            # when close the frame
    def closeEvent(self, event):
                # show a message box asking for confirmation
                reply = QtWidgets.QMessageBox.question(None, 'Smart AIoT',
                                                       "Are you sure you want to exit?", QtWidgets.QMessageBox.Yes |
                                                       QtWidgets.QMessageBox.No, QtWidgets.QMessageBox.No)
                if reply == QtWidgets.QMessageBox.Yes:
                    from App import MainWindow
                    print("go back to main menu")
                    self.window = QtWidgets.QFrame()
                    self.ui = MainWindow()
                    self.ui.setupUi(self.window)
                    self.window.show()
                    # Frame.Hide()

                else:
                    event.ignore()


# if __name__ == "__main__":
#         import sys,res
#         app = QtWidgets.QApplication(sys.argv)
#         Frame = QtWidgets.QFrame()
#         ui = facialRegister()
#         ui.setupUi(Frame)
#         Frame.show()
#         sys.exit(app.exec_())

