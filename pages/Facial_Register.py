# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'Register.ui'
#
# Created by: PyQt5 UI code generator 5.15.9
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets

# from Face_Recognition.JoloRecognition import JoloRecognition as JL

import os
import cv2
import time
import dlib
import torch
import numpy as np
import threading
from PyQt5.QtWidgets import *


class facialRegister(QtWidgets.QFrame):
    def __init__(self,parent=None):
            super().__init__(parent)

            # message box
            self.MessageBox = QtWidgets.QMessageBox()
            self.MessageBox.setStyleSheet("""
                  QMessageBox { 
                      text-align: center;
                  }
                  QMessageBox::icon {
                      subcontrol-position: center;
                  }
                  QPushButton { 
                      width: 250px; 
                      height: 30px; 
                      font-size: 15px;
                  }
              """)

            # EAR of eye
            self.blink_threshold = 0.3
            self.blink_counter = 0
            self.blink = True

            #frame
            self.setObjectName("facialRegistration")
            self.resize(800, 480)
            icon = QtGui.QIcon()
            icon.addPixmap(QtGui.QPixmap(":/background/Images/logo192x192.png"), QtGui.QIcon.Normal, QtGui.QIcon.Off)
            self.setWindowIcon(icon)
            self.setStyleSheet("background-color: rgb(231, 229, 213);\n"
            "background-image: url(:/background/Images/background-removebg-preview.png);\n"
            "background-position: center;\n"
            "")
        
            #camera
            self.widget = QtWidgets.QWidget(self)
            self.widget.setGeometry(QtCore.QRect(61, 60, 671, 361))
            self.widget.setStyleSheet("border: 2px solid rgb(61, 152, 154) ;\n"
            "border-radius: 50px;")
            self.widget.setObjectName("widget")
            self.horizontalLayoutWidget = QtWidgets.QWidget(self.widget)
            self.horizontalLayoutWidget.setGeometry(QtCore.QRect(20, 20, 631, 321))
            self.horizontalLayoutWidget.setObjectName("horizontalLayoutWidget")
            self.horizontalLayout = QtWidgets.QHBoxLayout(self.horizontalLayoutWidget)
            self.horizontalLayout.setContentsMargins(0, 0, 0, 0)
            self.horizontalLayout.setObjectName("horizontalLayout")

            # camera video label
            self.video = QtWidgets.QLabel(self.horizontalLayoutWidget)
            self.video.setStyleSheet("border:none;")
            self.video.setText("")
            self.video.setPixmap(QtGui.QPixmap(":/background/Images/loading.png"))
            self.video.setScaledContents(False)
            self.video.setAlignment(QtCore.Qt.AlignCenter)
            self.video.setObjectName("video")
            self.horizontalLayout.addWidget(self.video)
        

            self.cameraStat = False
            self.capture = 1
            
            
            # camera capture
            self.label = QtWidgets.QLabel(self)
            self.label.setGeometry(QtCore.QRect(370, 10, 41, 41))
            self.label.setText("")
            self.label.setPixmap(QtGui.QPixmap(":/background/Images/capture.png"))
            self.label.setAlignment(QtCore.Qt.AlignCenter)
            self.label.setObjectName("label")
        
            self.capture = QtWidgets.QLabel(self)
            self.capture.setGeometry(QtCore.QRect(410, 14, 21, 31))
            font = QtGui.QFont()
            font.setFamily("Segoe UI")
            font.setPointSize(12)
            font.setBold(True)
            font.setWeight(75)
            self.capture.setFont(font)
            self.capture.setStyleSheet("color: #3D989A")
            self.capture.setAlignment(QtCore.Qt.AlignCenter)
            self.capture.setObjectName("capture")
            
            # status
            self.status = QtWidgets.QLabel(self)
            self.status.setGeometry(QtCore.QRect(-10, 430, 811, 31))
            font = QtGui.QFont()
            font.setFamily("Segoe UI")
            font.setPointSize(12)
            font.setBold(True)
            font.setWeight(75)
            self.status.setFont(font)
            self.status.setStyleSheet("color: #3D989A")
            self.status.setAlignment(QtCore.Qt.AlignCenter)
            self.status.setObjectName("status")

            # open camera
            self.cap = cv2.VideoCapture(1) if cv2.VideoCapture(1).isOpened() else cv2.VideoCapture(0)
            self.cap.set(4, 1080)

            # face detector: Haar, dlib,landmark
            self.face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            self.dlib_faceDetcetoor = dlib.get_frontal_face_detector()
            self.landmark_detector = dlib.shape_predictor('Model/shape_predictor_68_face_landmarks.dat')


            # Timer
            self.timer = QtCore.QTimer(self)
            self.timer.timeout.connect(self.videoStreaming)
            self.last_recognition_time = time.time()
            self.timer.start(30)

            self.retranslateUi()
            QtCore.QMetaObject.connectSlotsByName(self)

    def retranslateUi(self):
        _translate = QtCore.QCoreApplication.translate
        self.setWindowTitle(_translate("facialRegistration", "Frame"))
        self.capture.setText(_translate("facialRegistration", "0"))
        self.status.setText(_translate("facialRegistration", "Please align your face properly"))



    # # capture and Train Images
    # def captureSave(self, current_time=None, frame=None,gray=None):

    #     # Check if camera is enabled
    #     if not self.cameraStat:
    #         return

    #     self.status.setText("Please blink" if self.capture >= 20 else "Face capture left " + str(21 - self.capture))


        
        
    #     # Set time delay to avoid over capturing
    #     if current_time - self.last_recognition_time <= 0.2:
    #         return

    #     self.last_recognition_time = current_time


    #             # Save captured images if capture count is less than 20
    #     if self.capture <= 20:

    #         path = f"Known_Faces/{self.textboxName.text()}/{self.capture}.png"
    #         cv2.imwrite(path, frame)
    #         self.capture += 1
                    
    #         return False
    #     else:
    #         return True

    # def facialTraining(self):

    #     # Train the facial recognition model
    #     message = JL().Face_Train()

    #             # Show the result
    #     title = "Facial Registration"
    #     text = "Facial training complete" if message == "Successfully trained" else message
    #     icon = self.MessageBox.Information if message == "Successfully trained" else self.MessageBox.Warning
    #     self.messageBoxShow(title=title, text=text, buttons=self.MessageBox.Ok, icon=icon)
    #     self.status.setText("Please create folder first")

    #     self.textboxName.setText("")

    #     self.create.setEnabled(True)
    #     self.textboxName.setReadOnly(False)

    #     self.cameraStat = False
    #     self.capture = 1

    # video Streaming
    def videoStreaming(self):
        ret, frame = self.cap.read()

        if not ret:
            self.camera.setText("Camera wont load")
            return

        # process the frame
        frame = cv2.flip(frame, 1)

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        


        # load facial detector haar
        faces = self.face_detector.detectMultiScale(gray,
                                                            scaleFactor=1.1,
                                                            minNeighbors=20,
                                                            minSize=(100, 100),
                                                            flags=cv2.CASCADE_SCALE_IMAGE)
        current_time = time.time()

        if self.cameraStat:
            
            # check if the frame is dark
            mean_value = cv2.mean(gray)[0]
            print(mean_value)
            if mean_value < 50:
                
                self.status.setText("It is too dark.")
                    
                height, width, channel = frame.shape
                bytesPerLine = channel * width
                qImg = QtGui.QImage(frame.data, width, height, bytesPerLine, QtGui.QImage.Format_BGR888)
                pixmap = QtGui.QPixmap.fromImage(qImg)
                self.video.setPixmap(pixmap)
                return
        
            # check if the frame is Bright
            if mean_value > 100:
                self.status.setText("It is too bright.")
                
                height, width, channel = frame.shape
                bytesPerLine = channel * width
                qImg = QtGui.QImage(frame.data, width, height, bytesPerLine, QtGui.QImage.Format_BGR888)
                pixmap = QtGui.QPixmap.fromImage(qImg)
                self.video.setPixmap(pixmap)
                return
        
        # if facial training is true
        if self.status.text() == "facial training":
            self.facialTraining()
            return
        
        if len(faces) == 1:
            x, y, w, h = faces[0]
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

        elif len(faces) >= 1:
            self.status.setText("Multiple face is detected")
        else:
            self.status.setText("No face is detected")

        height, width, channel = frame.shape
        bytesPerLine = channel * width
        qImg = QtGui.QImage(frame.data, width, height, bytesPerLine, QtGui.QImage.Format_BGR888)
        pixmap = QtGui.QPixmap.fromImage(qImg)
        self.video.setPixmap(pixmap)

            # message box
    # def messageBoxShow(self, icon=None, title=None, text=None, buttons=None):

    #             # Set the window icon, title, and text
    #             self.MessageBox.setIcon(icon)
    #             self.MessageBox.setWindowTitle(title)
    #             self.MessageBox.setText(text)

    #             # Set the window size
    #             self.MessageBox.setFixedWidth(400)

    #             # Set the standard buttons
    #             self.MessageBox.setStandardButtons(buttons)

    #             result = self.MessageBox.exec_()

    #             self.MessageBox.close()
    #             # Show the message box and return the result
    #             return result

    #         # create folder
    # def createButton(self):

    #             # Define the path for the known faces folder
    #             path = f"Known_Faces/{self.textboxName.text()}"

    #             if not self.textboxName.text():
    #                 self.messageBoxShow(
    #                     icon=self.MessageBox.Warning,
    #                     title="Facial Recognition",
    #                     text="Name cannot be empty",
    #                     buttons=self.MessageBox.Ok
    #                 )
    #                 return

    #             # Check if the folder already exists
    #             if os.path.exists(path):
    #                 # Show a message box indicating that the folder already exists
    #                 self.messageBoxShow(
    #                     icon=self.MessageBox.Warning,
    #                     title="Facial Recognition",
    #                     text="Folder already exists",
    #                     buttons=self.MessageBox.Ok
    #                 )

    #                 # Disable the push button and plain text edit
    #                 pushButtonEnabled = False
    #                 plainTextEditEnabled = False

    #                 # Set the camera status to true
    #                 self.cameraStat = False
    #             else:

    #                 # Create the known faces folder if it doesn't exist
    #                 os.makedirs(path, exist_ok=True)

    #                 # Show a message box indicating that the folder has been created
    #                 self.messageBoxShow(
    #                     icon=self.MessageBox.Information,
    #                     title="Facial Recognition",
    #                     text="Folder Created please align your face to camera properly",
    #                     buttons=self.MessageBox.Ok
    #                 )

    #                 # Enable the camera and plain text edit
    #                 pushButtonEnabled = False
    #                 plainTextEditEnabled = True

    #                 # Set the camera status to true
    #                 self.cameraStat = True

    #             # Update the enabled status of the push button and plain text edit
    #             self.create.setEnabled(pushButtonEnabled)
    #             self.textboxName.setReadOnly(plainTextEditEnabled)

    #         # =================== for eye blinking detection functions =================== #
    # def eyeBlink(self, gray, frame):

    #     # detect eyes using dlib
    #     faces = self.dlib_faceDetcetoor(gray, 0)
    #     status = None
    #     for face in faces:
    #         landmarks = self.landmark_detector(gray, face)

    #         # extract eye coordinates from facial landmarks
    #         left_eye, right_eye = self.extract_eye_coordinates(landmarks)

    #         # calculate eye aspect ratio
    #         ear = self.calculate_ear(left_eye, right_eye)

    #         # update blink count and status
    #         status = self.update_blink_count_and_status(ear)


    #     return self.blink

    # def extract_eye_coordinates(self, landmarks):
    #     left_eye = []
    #     right_eye = []

    #     for i in range(36, 42):
    #         left_eye.append((landmarks.part(i).x, landmarks.part(i).y))

    #     for i in range(42, 48):
    #         right_eye.append((landmarks.part(i).x, landmarks.part(i).y))

    #     return left_eye, right_eye

    # def EAR_cal(self, eye):
    #     eye = torch.from_numpy(np.array(eye)).float()

    #     # ------- verticle ------- #
    #     v1 = torch.dist(eye[1], eye[5])
    #     v2 = torch.dist(eye[2], eye[4])

    #     # ------- horizontal ------- #
    #     h1 = torch.dist(eye[0], eye[3])

    #     ear = (v1 + v2) / h1
    #     return ear

    # def calculate_ear(self, left_eye, right_eye):

    #     LEFT = self.EAR_cal(left_eye)
    #     RIGHT = self.EAR_cal(right_eye)

    #     EAR = float((LEFT + RIGHT) / 2.0)

    #     return round(EAR, 2)

    # def update_blink_count_and_status(self, ear):
    #     if ear < self.blink_threshold:

    #         # if eye is once Open
    #         if self.blink:
    #             self.blink_counter += 1
    #             self.blink = False

    #             self.status.setText("Facial Training")
    #             return False
    #         else:
    #             # if eye is open
    #             self.status.setText("Please Blink")
    #             self.blink = True
    #             return True



    # # when close the frame
    # def closeEvent(self, event):
    #     from pages.Main_Menu import MainWindow
    #     print("go back to main menu")

    #     self.resize(555, 495)
        
    #     self.cap.release()
    #     cv2.destroyAllWindows()
    #     MainWindow(self).show()
        
        
    #     self.close()




if __name__ == "__main__":

    import sys,background
    # Create a new QApplication object
    app = QApplication(sys.argv)

    New_menu = facialRegister()
    New_menu.show()

    sys.exit(app.exec_())
