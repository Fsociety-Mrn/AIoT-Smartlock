# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'Register.ui'
#
# Created by: PyQt5 UI code generator 5.15.9
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets

from Face_Recognition.JoloRecognition import JoloRecognition as JL

import os
import cv2
import time
import dlib
import torch
import numpy as np
import threading
from PyQt5.QtWidgets import *


class facialRegister(QFrame):
    def __init__(self,parent=None):
            super().__init__(parent)

            # message box
            self.MessageBox = QtWidgets.QMessageBox()
            self.MessageBox.setStyleSheet("""
                  QMessageBox { 
                      text-align: center;
                  }
                  QMessageBox::icon {
                      subcontrol-position: center;
                  }
                  QPushButton { 
                      width: 250px; 
                      height: 30px; 
                      font-size: 15px;
                  }
              """)

            # EAR of eye
            self.blink_threshold = 0.3
            self.blink_counter = 0
            self.blink = True

            #frame
            self.setObjectName("Facial register")
            self.resize(533, 643)
            self.setStyleSheet("background-color: qlineargradient(spread:pad, x1:0, y1:0, x2:0.0965909, y2:0.909, stop:0 rgba(61, 152, 154, 255), stop:1 rgba(12, 14, 36, 255));")
            
            #camera
            self.camera = QtWidgets.QLabel(self)
            self.camera.setGeometry(QtCore.QRect(10, 20, 501, 341))
            self.camera.setStyleSheet("color: white;\n""")
            self.camera.setAlignment(QtCore.Qt.AlignCenter)
            self.camera.setObjectName("camera")

            self.cameraStat = False
            self.capture = 1

            # open camera
            self.cap = cv2.VideoCapture(1) if cv2.VideoCapture(1).isOpened() else cv2.VideoCapture(0)
            self.cap.set(4, 1080)

            # face detector: Haar, dlib,landmark
            self.face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            self.dlib_faceDetcetoor = dlib.get_frontal_face_detector()
            self.landmark_detector = dlib.shape_predictor('Model/shape_predictor_68_face_landmarks.dat')

            #status
            self.status = QtWidgets.QLabel(self)
            self.status.setGeometry(QtCore.QRect(10, 380, 501, 41))
            self.status.setStyleSheet("color: white;\n""")
            self.status.setAlignment(QtCore.Qt.AlignCenter)
            self.status.setObjectName("status")

            # textbox name
            self.textboxName = QtWidgets.QLineEdit(self)
            self.textboxName.setGeometry(QtCore.QRect(10, 460, 511, 61))
            self.textboxName.setStyleSheet("color: white;\n""")
            self.textboxName.setAlignment(QtCore.Qt.AlignCenter)
            self.textboxName.setObjectName("textboxName")

            # create button
            self.create = QtWidgets.QPushButton(self)
            self.create.setGeometry(QtCore.QRect(40, 530, 451, 41))
            self.create.setStyleSheet("color: white;\n""")
            self.create.setObjectName("create")
            self.create.clicked.connect(self.createButton)

            # back to main
            self.backTomain = QtWidgets.QPushButton(self)
            self.backTomain.setGeometry(QtCore.QRect(40, 600-20, 451, 41))
            self.backTomain.setStyleSheet("color: white;\n""")
            self.backTomain.setObjectName("create")
            self.backTomain.clicked.connect(self.closeEvent)

            # connect the close event to the method
            self.closeEvent = self.closeEvent

            # Timer
            self.timer = QtCore.QTimer(self)
            self.timer.timeout.connect(self.videoStreaming)
            self.last_recognition_time = time.time()
            self.timer.start(30)

            self.retranslateUi(self)
            QtCore.QMetaObject.connectSlotsByName(self)

    def retranslateUi(self, Frame):
        _translate = QtCore.QCoreApplication.translate
        Frame.setWindowTitle(_translate("Frame", "Frame"))

        # for camera
        self.camera.setText(_translate("Frame", "Loading"))

        # message status
        self.status.setText(_translate("Frame", "Please create folder first"))

        # create Button
        self.create.setText(_translate("Frame", "Create folder"))

        # back to main
        self.backTomain.setText(_translate("Frame", "back to main menu"))


    # capture and Train Images
    def captureSave(self, current_time=None, frame=None,gray=None):

        # Check if camera is enabled
        if not self.cameraStat:
            return

        self.status.setText("Please blink" if self.capture >= 20 else "Face capture left " + str(21 - self.capture))


        
        
        # Set time delay to avoid over capturing
        if current_time - self.last_recognition_time <= 0.2:
            return

        self.last_recognition_time = current_time


                # Save captured images if capture count is less than 20
        if self.capture <= 20:

            path = f"Known_Faces/{self.textboxName.text()}/{self.capture}.png"
            cv2.imwrite(path, frame)
            self.capture += 1
                    
            return False
        else:
            return True

    def facialTraining(self):

        # Train the facial recognition model
        message = JL().Face_Train()

                # Show the result
        title = "Facial Registration"
        text = "Facial training complete" if message == "Successfully trained" else message
        icon = self.MessageBox.Information if message == "Successfully trained" else self.MessageBox.Warning
        self.messageBoxShow(title=title, text=text, buttons=self.MessageBox.Ok, icon=icon)
        self.status.setText("Please create folder first")

        self.textboxName.setText("")

        self.create.setEnabled(True)
        self.textboxName.setReadOnly(False)

        self.cameraStat = False
        self.capture = 1

    # video Streaming
    def videoStreaming(self):
        ret, frame = self.cap.read()

        if not ret:
            self.camera.setText("Camera wont load")
            return

        # process the frame
        frame = cv2.flip(frame, 1)

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        


                # load facial detector haar
        faces = self.face_detector.detectMultiScale(gray,
                                                            scaleFactor=1.1,
                                                            minNeighbors=20,
                                                            minSize=(100, 100),
                                                            flags=cv2.CASCADE_SCALE_IMAGE)
        current_time = time.time()

        if self.cameraStat:
            
            # check if the frame is dark
            mean_value = cv2.mean(gray)[0]
            print(mean_value)
            if mean_value < 50:
                
                self.status.setText("It is too dark.")
                    
                height, width, channel = frame.shape
                bytesPerLine = channel * width
                qImg = QtGui.QImage(frame.data, width, height, bytesPerLine, QtGui.QImage.Format_BGR888)
                pixmap = QtGui.QPixmap.fromImage(qImg)
                self.camera.setPixmap(pixmap)
                return
        
            # check if the frame is Bright
            if mean_value > 100:
                self.status.setText("It is too bright.")
                
                height, width, channel = frame.shape
                bytesPerLine = channel * width
                qImg = QtGui.QImage(frame.data, width, height, bytesPerLine, QtGui.QImage.Format_BGR888)
                pixmap = QtGui.QPixmap.fromImage(qImg)
                self.camera.setPixmap(pixmap)
                return
        
        # if facial training is true
        if self.status.text() == "facial training":
            self.facialTraining()
            return
        
        if len(faces) == 1:
            x, y, w, h = faces[0]
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            self.status.setText("Please create folder first")

                    # if not self.eyeBlink(frame=frame,gray=gray):
            statusCap = self.captureSave(current_time=current_time, frame=frame, gray=gray)

            if statusCap:
                print(self.eyeBlink(frame=frame,gray=gray))
                if not self.eyeBlink(frame=frame,gray=gray) == None and self.eyeBlink(frame=frame,gray=gray) == False:
                    # print("facial training")
                    self.camera.setText("Please bear with me")
                    self.status.setText("facial training")
                    return
                    
            



        elif len(faces) >= 1:
            self.status.setText("Multiple face is detected")
        else:
            self.status.setText("No face is detected")

        height, width, channel = frame.shape
        bytesPerLine = channel * width
        qImg = QtGui.QImage(frame.data, width, height, bytesPerLine, QtGui.QImage.Format_BGR888)
        pixmap = QtGui.QPixmap.fromImage(qImg)
        self.camera.setPixmap(pixmap)

            # message box
    def messageBoxShow(self, icon=None, title=None, text=None, buttons=None):

                # Set the window icon, title, and text
                self.MessageBox.setIcon(icon)
                self.MessageBox.setWindowTitle(title)
                self.MessageBox.setText(text)

                # Set the window size
                self.MessageBox.setFixedWidth(400)

                # Set the standard buttons
                self.MessageBox.setStandardButtons(buttons)

                result = self.MessageBox.exec_()

                self.MessageBox.close()
                # Show the message box and return the result
                return result

            # create folder
    def createButton(self):

                # Define the path for the known faces folder
                path = f"Known_Faces/{self.textboxName.text()}"

                if not self.textboxName.text():
                    self.messageBoxShow(
                        icon=self.MessageBox.Warning,
                        title="Facial Recognition",
                        text="Name cannot be empty",
                        buttons=self.MessageBox.Ok
                    )
                    return

                # Check if the folder already exists
                if os.path.exists(path):
                    # Show a message box indicating that the folder already exists
                    self.messageBoxShow(
                        icon=self.MessageBox.Warning,
                        title="Facial Recognition",
                        text="Folder already exists",
                        buttons=self.MessageBox.Ok
                    )

                    # Disable the push button and plain text edit
                    pushButtonEnabled = False
                    plainTextEditEnabled = False

                    # Set the camera status to true
                    self.cameraStat = False
                else:

                    # Create the known faces folder if it doesn't exist
                    os.makedirs(path, exist_ok=True)

                    # Show a message box indicating that the folder has been created
                    self.messageBoxShow(
                        icon=self.MessageBox.Information,
                        title="Facial Recognition",
                        text="Folder Created please align your face to camera properly",
                        buttons=self.MessageBox.Ok
                    )

                    # Enable the camera and plain text edit
                    pushButtonEnabled = False
                    plainTextEditEnabled = True

                    # Set the camera status to true
                    self.cameraStat = True

                # Update the enabled status of the push button and plain text edit
                self.create.setEnabled(pushButtonEnabled)
                self.textboxName.setReadOnly(plainTextEditEnabled)

            # =================== for eye blinking detection functions =================== #
    def eyeBlink(self, gray, frame):

        # detect eyes using dlib
        faces = self.dlib_faceDetcetoor(gray, 0)
        status = None
        for face in faces:
            landmarks = self.landmark_detector(gray, face)

            # extract eye coordinates from facial landmarks
            left_eye, right_eye = self.extract_eye_coordinates(landmarks)

            # calculate eye aspect ratio
            ear = self.calculate_ear(left_eye, right_eye)

            # update blink count and status
            status = self.update_blink_count_and_status(ear)


        return self.blink

    def extract_eye_coordinates(self, landmarks):
        left_eye = []
        right_eye = []

        for i in range(36, 42):
            left_eye.append((landmarks.part(i).x, landmarks.part(i).y))

        for i in range(42, 48):
            right_eye.append((landmarks.part(i).x, landmarks.part(i).y))

        return left_eye, right_eye

    def EAR_cal(self, eye):
        eye = torch.from_numpy(np.array(eye)).float()

        # ------- verticle ------- #
        v1 = torch.dist(eye[1], eye[5])
        v2 = torch.dist(eye[2], eye[4])

        # ------- horizontal ------- #
        h1 = torch.dist(eye[0], eye[3])

        ear = (v1 + v2) / h1
        return ear

    def calculate_ear(self, left_eye, right_eye):

        LEFT = self.EAR_cal(left_eye)
        RIGHT = self.EAR_cal(right_eye)

        EAR = float((LEFT + RIGHT) / 2.0)

        return round(EAR, 2)

    def update_blink_count_and_status(self, ear):
        if ear < self.blink_threshold:

            # if eye is once Open
            if self.blink:
                self.blink_counter += 1
                self.blink = False

                self.status.setText("Facial Training")
                return False
            else:
                # if eye is open
                self.status.setText("Please Blink")
                self.blink = True
                return True



    # when close the frame
    def closeEvent(self, event):
        from pages.Main_Menu import MainWindow
        print("go back to main menu")

        self.resize(555, 495)
        
        self.cap.release()
        cv2.destroyAllWindows()
        MainWindow(self).show()
        
        
        self.close()




if __name__ == "__main__":
    # Create a new QApplication object
    import sys
    app = QApplication(sys.argv)

    New_menu = facialRegister()
    New_menu.show()

    sys.exit(app.exec_())

